{
     "cells": [
      {
       "cell_type": "code",
       "execution_count": 1,
       "metadata": {},
       "outputs": [
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "17b1c53092644ed9a22c6dc307ab1589",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": [
           "Downloading readme:   0%|          | 0.00/137 [00:00<?, ?B/s]"
          ]
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "Downloading and preparing dataset csv/neelblabla--enron_labeled_emails_with_subjects-llama2-7b_finetuning to C:/Users/Nico/.cache/huggingface/datasets/neelblabla___csv/neelblabla--enron_labeled_emails_with_subjects-llama2-7b_finetuning-588225da544adb11/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
         ]
        },
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "e0b0f5f8fd924e0d976a34151efa6a11",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": [
           "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "a8f807a1e48b4c71a80788db10eb523c",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": [
           "Downloading data:   0%|          | 0.00/6.77M [00:00<?, ?B/s]"
          ]
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "95e7ef99c5224807a3701fdeeef472ff",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": [
           "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "e9b3f1e5baf346caa1051535e1bf62aa",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": [
           "Generating train split: 0 examples [00:00, ? examples/s]"
          ]
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "Dataset csv downloaded and prepared to C:/Users/Nico/.cache/huggingface/datasets/neelblabla___csv/neelblabla--enron_labeled_emails_with_subjects-llama2-7b_finetuning-588225da544adb11/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
         ]
        },
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "94f4b370e43f4e22a3765b4c63102d9f",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": [
           "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "<class 'datasets.dataset_dict.DatasetDict'>\n",
          "DatasetDict({\n",
          "    train: Dataset({\n",
          "        features: ['prompts'],\n",
          "        num_rows: 1400\n",
          "    })\n",
          "})\n"
         ]
        }
       ],
       "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"neelblabla/enron_labeled_emails_with_subjects-llama2-7b_finetuning\")\n",
        "\n",
        "print(type(dataset))\n",
        "print(dataset)"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 63,
       "metadata": {},
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "(('RE: NERC Meeting Today', 'There was an all day meeting of the NERC/reliability legislation group today. I will provide a more detailed report but the group completed the process of reviewing the changes that some had suggested to shorten and streamline the NERC electric reliability organization legislation. Sarah and I asked a series of questions and made comments on our key issues and concerns. I want to give you a more complete report once I have gone back over the now final draft version. The timing being imposed by NERC is that they will circulate a clean version of the proposal tomorrow or Monday. They have asked for comments by next Thursday August 16th with an indication of whether each company/organization does or does not sign on to support it. They will then transmit the proposal and the endorsement letter to Congress and the Administration so they have it as Hill and Energy Dept. staff work on electricity drafting issues this month. I pointed out that EPSA is not due to meet internally with its members to discuss these issues until after the NERC deadline. That is not deterring NERC from moving forward with the above time frame.'),)\n"
         ]
        }
       ],
       "source": [
        "import pandas as pd\n",
        "import re\n",
        "df_pandas = pd.DataFrame(dataset)\n",
        "f = []\n",
        "pattern =  r'Subject:: (.+)\\nBody:: (.+)'\n",
        "for i in range(len(df_pandas)):\n",
        "     matches = re.findall(pattern, df_pandas.iloc[i][0]['prompts'])\n",
        "     if matches:\n",
        "          f.append(tuple(matches))\n",
        "print(f[1])"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 70,
       "metadata": {},
       "outputs": [],
       "source": [
        "# Convert the list of tuples into a DataFrame with a single column\n",
        "finalDataframe = pd.DataFrame(f, columns=['Data'])\n",
        "\n",
        "# Split the single column into two columns\n",
        "finalDataframe[['Subject', 'Body']] = pd.DataFrame(finalDataframe['Data'].tolist(), index=finalDataframe.index)\n",
        "\n",
        "# Drop the original single column\n",
        "finalDataframe.drop(columns=['Data'], inplace=True)"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 76,
       "metadata": {},
       "outputs": [
        {
         "data": {
          "text/plain": [
           "'I agree with Joe. The IOUs will point to NERC as an objective third party on these issues. '"
          ]
         },
         "execution_count": 76,
         "metadata": {},
         "output_type": "execute_result"
        }
       ],
       "source": [
        "finalDataframe.iloc[0]['Body']"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 73,
       "metadata": {},
       "outputs": [],
       "source": [
        "finalDataframe.to_csv('out.csv', index=False)"
       ]
      }
     ],
     "metadata": {
      "kernelspec": {
       "display_name": "base",
       "language": "python",
       "name": "python3"
      },
      "language_info": {
       "codemirror_mode": {
        "name": "ipython",
        "version": 3
       },
       "file_extension": ".py",
       "mimetype": "text/x-python",
       "name": "python",
       "nbconvert_exporter": "python",
       "pygments_lexer": "ipython3",
       "version": "3.9.13"
      }
     },
     "nbformat": 4,
     "nbformat_minor": 2
    }
    